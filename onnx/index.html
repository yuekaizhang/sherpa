<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sherpa-onnx &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Installation" href="install/index.html" />
    <link rel="prev" title="FAQs" href="../ncnn/faq.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">sherpa-onnx</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="websocket/index.html">WebSocket</a></li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/index.html">Pre-trained models</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>sherpa-onnx</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sherpa-onnx">
<h1>sherpa-onnx<a class="headerlink" href="#sherpa-onnx" title="Permalink to this headline">ÔÉÅ</a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>During speech recognition, it does not need to access the Internet.
Everyting is processed locally on your device.</p>
</div>
<p>We support using <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> with <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> to replace <a class="reference external" href="https://pytorch.org/">PyTorch</a> for neural
network computation. The code is put in a separate repository <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a> is self-contained and everything can be compiled from source.</p>
<p>Please refer to
<a class="reference external" href="https://k2-fsa.github.io/icefall/model-export/export-onnx.html">https://k2-fsa.github.io/icefall/model-export/export-onnx.html</a>
for how to export models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> format.</p>
<p>In the following, we describe how to build <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a> for Linux, macOS,
Windows, embedded systems, Android, and iOS.</p>
<p>Also, we show how to use it for speech recognition with pre-trained models.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install/linux.html">Linux</a></li>
<li class="toctree-l2"><a class="reference internal" href="install/macos.html">macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="install/windows.html">Windows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/windows.html#bit-windows-x64">64-bit Windows (x64)</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/windows.html#bit-windows-x86">32-bit Windows (x86)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install/aarch64-embedded-linux.html">Embedded Linux (aarch64)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#sherpa-onnx-alsa">sherpa-onnx-alsa</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install/arm-embedded-linux.html">Embedded Linux (arm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/arm-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/arm-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="python/index.html">Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="python/install.html">Install the Python Package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-1-from-pre-compiled-wheels">Method 1 (From pre-compiled wheels)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-2-from-source">Method 2 (From source)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-3-for-developers">Method 3 (For developers)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#check-your-installation">Check your installation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/decode-files.html">Decode files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/decode-files.html#streaming-zipformer">Streaming zipformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/decode-files.html#non-streaming-zipformer">Non-streaming zipformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/decode-files.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/real-time-speech-recongition-from-a-microphone.html">Real-time speech recognition from a microphone</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/real-time-speech-recongition-from-a-microphone.html#with-endpoint-detection">With endpoint detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/real-time-speech-recongition-from-a-microphone.html#without-endpoint-detection">Without endpoint detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/speech-recognition-from-urls.html">Speech recognition from URLs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/speech-recognition-from-urls.html#decode-a-url">Decode a URL</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/speech-recognition-from-urls.html#rtmp">RTMP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#install-the-server">Install the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#start-the-server">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#start-ffmpeg-to-push-audio-stream">Start ffmpeg to push audio stream</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#start-sherpa-onnx-to-pull-audio-stream">Start sherpa-onnx to pull audio stream</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="c-api/index.html">C API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html#generate-required-files">Generate required files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="c-api/index.html#build-shared-libraries">Build shared libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="c-api/index.html#build-static-libraries">Build static libraries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html#build-decode-file-c-api-c-with-generated-files">Build decode-file-c-api.c with generated files</a></li>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="android/index.html">Android</a><ul>
<li class="toctree-l2"><a class="reference internal" href="android/build-sherpa-onnx.html">Build sherpa-onnx for Android</a><ul>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#install-android-studio">Install Android Studio</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#download-sherpa-onnx">Download sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#install-ndk">Install NDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#build-sherpa-onnx-c-code">Build sherpa-onnx (C++ code)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-arm64-v8a">Build for arm64-v8a</a></li>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-armv7-eabi">Build for armv7-eabi</a></li>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-x86-64">Build for x86_64</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#download-pre-trained-models">Download pre-trained models</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#generate-apk">Generate APK</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#analyze-the-apk">Analyze the APK</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ios/index.html">iOS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html">Build sherpa-onnx for iOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#requirement">Requirement</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#download-sherpa-onnx">Download sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#build-sherpa-onnx-in-commandline-c-part">Build sherpa-onnx (in commandline, C++ Part)</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#build-sherpa-onnx-in-xcode">Build sherpa-onnx (in Xcode)</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#run-sherpa-onnx-on-your-iphone-ipad">Run sherpa-onnx on your iPhone/iPad</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="websocket/index.html">WebSocket</a><ul>
<li class="toctree-l2"><a class="reference internal" href="websocket/online-websocket.html">Streaming WebSocket server and client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#build-sherpa-onnx-with-websocket-support">Build <cite>sherpa-onnx</cite> with WebSocket support</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#view-the-server-usage">View the server usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-server">Start the server</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#view-the-usage-of-the-client-c">View the usage of the client (C++)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-client-c">Start the client (C++)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#view-the-usage-of-the-client-python">View the usage of the client (Python)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-client-python">Start the client (Python)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-client-python-with-microphone">Start the client (Python, with microphone)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="websocket/offline-websocket.html">Non-streaming WebSocket server and client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#build-sherpa-onnx-with-websocket-support">Build <cite>sherpa-onnx</cite> with WebSocket support</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#view-the-server-usage">View the server usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#start-the-server">Start the server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#start-the-server-with-a-transducer-model">Start the server with a transducer model</a></li>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#start-the-server-with-a-paraformer-model">Start the server with a paraformer model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#start-the-client-python">Start the client (Python)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#id1">offline-websocket-client-decode-files-paralell.py</a></li>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#id2">offline-websocket-client-decode-files-sequential.py</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/online-transducer/index.html">Online transducer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#pkufool-icefall-asr-zipformer-streaming-wenetspeech-20230615-chinese">pkufool/icefall-asr-zipformer-streaming-wenetspeech-20230615 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-06-26-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id2">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id5">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-06-21-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-06-21 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id7">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id10">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-02-21-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-02-21 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id11">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id12">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id15">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english">csukuangfj/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20 (Bilingual, Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id16">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id17">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id20">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french">shaojieli/sherpa-onnx-streaming-zipformer-fr-2023-04-14 (French)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id21">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id22">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id25">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html">Conformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-conformer-zh-2023-05-23-chinese">csukuangfj/sherpa-onnx-streaming-conformer-zh-2023-05-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html">LSTM-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#csukuangfj-sherpa-onnx-lstm-en-2023-02-17-english">csukuangfj/sherpa-onnx-lstm-en-2023-02-17 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#csukuangfj-sherpa-onnx-lstm-zh-2023-02-20-chinese">csukuangfj/sherpa-onnx-lstm-zh-2023-02-20 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id2">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id5">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/offline-transducer/index.html">Offline transducer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#yfyeung-icefall-asr-cv-corpus-13-0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17-english">yfyeung/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#pkufool-icefall-asr-zipformer-wenetspeech-20230615-chinese">pkufool/icefall-asr-zipformer-wenetspeech-20230615 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id2">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id5">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-large-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-large-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id7">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id10">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-small-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-small-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id12">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id13">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id16">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id18">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id19">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id22">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#icefall-asr-multidataset-pruned-transducer-stateless7-2023-05-04-english">icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id24">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id25">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id28">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-04-01-english">csukuangfj/sherpa-onnx-zipformer-en-2023-04-01 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id29">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id30">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id33">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-03-30-english">csukuangfj/sherpa-onnx-zipformer-en-2023-03-30 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id34">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id35">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id38">Speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html">Conformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-zh-stateless2-2023-05-23-chinese">csukuangfj/sherpa-onnx-conformer-zh-stateless2-2023-05-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-zh-2023-05-23-chinese">csukuangfj/sherpa-onnx-conformer-zh-2023-05-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id2">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id5">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-en-2023-03-18-english">csukuangfj/sherpa-onnx-conformer-en-2023-03-18 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id7">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id10">Speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/offline-paraformer/index.html">Offline paraformer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-03-28-chinese">csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/offline-ctc/index.html">Offline CTC models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/index.html">NeMo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html">How to export models from NeMo to sherpa-onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-1-export-model-onnx">Step 1: Export model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-2-add-metadata">Step 2: Add metadata</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-3-obtain-model-int8-onnx">Step 3: Obtain model.int8.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-4-obtain-tokens-txt">Step 4: Obtain tokens.txt</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html">English</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-citrinet-512">stt_en_citrinet_512</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-small">stt_en_conformer_ctc_small</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-medium">stt_en_conformer_ctc_medium</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-large">stt_en_conformer_ctc_large</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/index.html">Whisper</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html">Export Whisper to ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#available-models">Available models</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#export-to-onnx">Export to onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/tiny.en.html">tiny.en</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/tiny.en.html#real-time-factor-rtf-on-raspberry-pi-4-model-b">Real-time factor (RTF) on Raspberry Pi 4 Model B</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/colab.html">colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/huggingface.html">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../ncnn/faq.html" class="btn btn-neutral float-left" title="FAQs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="install/index.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>