<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Export Whisper to ONNX &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="tiny.en" href="tiny.en.html" />
    <link rel="prev" title="Whisper" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">sherpa-onnx</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../go-api/index.html">Go API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../csharp-api/index.html">C# API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websocket/index.html">WebSocket</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Pre-trained models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../online-transducer/index.html">Online transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-paraformer/index.html">Online paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-transducer/index.html">Offline transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-paraformer/index.html">Offline paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-ctc/index.html">Offline CTC models</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Whisper</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Export Whisper to ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="tiny.en.html">tiny.en</a></li>
<li class="toctree-l4"><a class="reference internal" href="colab.html">colab</a></li>
<li class="toctree-l4"><a class="reference internal" href="huggingface.html">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">sherpa-onnx</a> &raquo;</li>
          <li><a href="../index.html">Pre-trained models</a> &raquo;</li>
          <li><a href="index.html">Whisper</a> &raquo;</li>
      <li>Export Whisper to ONNX</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/pretrained_models/whisper/export-onnx.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="export-whisper-to-onnx">
<h1>Export Whisper to ONNX<a class="headerlink" href="#export-whisper-to-onnx" title="Permalink to this headline"></a></h1>
<p>This section describes how to export <a class="reference external" href="https://github.com/openai/whisper/">Whisper</a> models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>.</p>
<section id="available-models">
<h2>Available models<a class="headerlink" href="#available-models" title="Permalink to this headline"></a></h2>
<p>Note that we have already exported <a class="reference external" href="https://github.com/openai/whisper/">Whisper</a> models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> and they are available
from the following huggingface repositories:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Model type</p></td>
<td><p>Huggingface repo</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tiny.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">base.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-base.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-base.en</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">small.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-small.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-small.en</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">medium.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium.en</a></p></td>
</tr>
</tbody>
</table>
<p>If you want to export the models by yourself or/and want to learn how the models
are exported, please read below.</p>
</section>
<section id="export-to-onnx">
<h2>Export to onnx<a class="headerlink" href="#export-to-onnx" title="Permalink to this headline"></a></h2>
<p>We use</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/export-onnx.py">https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/export-onnx.py</a></p>
</div></blockquote>
<p>to export <a class="reference external" href="https://github.com/openai/whisper/">Whisper</a> models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>.</p>
<p>First, let us install dependencies and download the export script</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>openai-whisper<span class="w"> </span>onnxruntime<span class="w"> </span>onnx

git<span class="w"> </span>clone<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/
<span class="nb">cd</span><span class="w"> </span>sherpa-onnx/scripts/whisper
python3<span class="w"> </span>./export-onnx.py<span class="w"> </span>--help
</pre></div>
</div>
<p>It will print the following message:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage:<span class="w"> </span>export-onnx.py<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span>--model<span class="w"> </span><span class="o">{</span>tiny,tiny.en,base,base.en,small,small.en,medium,medium.en,large,large-v1,large-v2<span class="o">}</span>

optional<span class="w"> </span>arguments:
<span class="w">  </span>-h,<span class="w"> </span>--help<span class="w">            </span>show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>--model<span class="w"> </span><span class="o">{</span>tiny,tiny.en,base,base.en,small,small.en,medium,medium.en,large,large-v1,large-v2<span class="o">}</span>
</pre></div>
</div>
<p>To export <code class="docutils literal notranslate"><span class="pre">tiny.en</span></code>, we can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>./export-onnx.py<span class="w"> </span>--model<span class="w"> </span>tiny.en
</pre></div>
</div>
<p>It will generate the following files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>py38<span class="o">)</span><span class="w"> </span>fangjuns-MacBook-Pro:whisper<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>tiny.en-*
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>105M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-decoder.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>185M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-decoder.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>12M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-encoder.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>36M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-encoder.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>816K<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-tokens.txt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tiny.en-encoder.onnx</span></code> is the encoder model and <code class="docutils literal notranslate"><span class="pre">tiny.en-decoder.onnx</span></code> is the
decoder model.</p>
<p><code class="docutils literal notranslate"><span class="pre">tiny.en-encoder.int8.onnx</span></code> is the quantized encoder model and <code class="docutils literal notranslate"><span class="pre">tiny.en-decoder.onnx</span></code> is the
quantized decoder model.</p>
<p><code class="docutils literal notranslate"><span class="pre">tiny.en-tokens.txt</span></code> contains the token table, which maps an integer to a token and vice versa.</p>
<p>To convert the exported <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> model to <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> format, we can use</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>onnxruntime.tools.convert_onnx_models_to_ort<span class="w"> </span>--optimization_style<span class="o">=</span>Fixed<span class="w"> </span>./
</pre></div>
</div>
<p>Now the generated files so far are as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(py38) fangjuns-MacBook-Pro:whisper fangjun$ ls -lh tiny.en-*
-rw-r--r--  1 fangjun  staff   105M Aug  7 15:43 tiny.en-decoder.int8.onnx
-rw-r--r--  1 fangjun  staff   105M Aug  7 15:45 tiny.en-decoder.int8.ort
-rw-r--r--  1 fangjun  staff   185M Aug  7 15:43 tiny.en-decoder.onnx
-rw-r--r--  1 fangjun  staff   185M Aug  7 15:45 tiny.en-decoder.ort
-rw-r--r--  1 fangjun  staff    12M Aug  7 15:43 tiny.en-encoder.int8.onnx
-rw-r--r--  1 fangjun  staff    12M Aug  7 15:45 tiny.en-encoder.int8.ort
-rw-r--r--  1 fangjun  staff    36M Aug  7 15:43 tiny.en-encoder.onnx
-rw-r--r--  1 fangjun  staff    36M Aug  7 15:45 tiny.en-encoder.ort
-rw-r--r--  1 fangjun  staff   816K Aug  7 15:43 tiny.en-tokens.txt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">*.ort</span></code> are the corresponding <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> format.</p>
<p>To check whether the export model works correctly, we can use</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/test.py">https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/test.py</a></p>
</div></blockquote>
<p>We use <a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav</a>
as the test wave.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>kaldi-native-fbank
wget<span class="w"> </span>https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav

python3<span class="w"> </span>./test.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="w"> </span>./tiny.en-encoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="w"> </span>./tiny.en-decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span>./tiny.en-tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./0.wav
</pre></div>
</div>
<p>To test <code class="docutils literal notranslate"><span class="pre">int8</span></code> quantized models, we can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>./test.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="w"> </span>./tiny.en-encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="w"> </span>./tiny.en-decoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span>./tiny.en-tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./0.wav
</pre></div>
</div>
<p>To test models of <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> format, we can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>./test.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="w"> </span>./tiny.en-encoder.int8.ort<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="w"> </span>./tiny.en-decoder.int8.ort<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span>./tiny.en-tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./0.wav
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Whisper" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tiny.en.html" class="btn btn-neutral float-right" title="tiny.en" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>