<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Zipformer-transducer-based Models &mdash; sherpa 1.2 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Conformer-transducer-based Models" href="conformer-transducer-models.html" />
    <link rel="prev" title="Online transducer models" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">For Python users</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../python/huggingface/index.html">Try sherpa with Huggingface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/streaming_asr/index.html">Streaming ASR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/offline_asr/index.html">Non-streaming speech recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/faq.html">Frequently asked questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For C++ users</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp/installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp/pretrained_models/index.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">sherpa-onnx</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websocket/index.html">WebSocket</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Pre-trained models</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Online transducer models</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Zipformer-transducer-based Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="conformer-transducer-models.html">Conformer-transducer-based Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="lstm-transducer-models.html">LSTM-transducer-based Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../offline-transducer/index.html">Offline transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-paraformer/index.html">Offline paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-ctc/index.html">Offline CTC models</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/server/index.html">Triton-server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/client/index.html">Triton-client</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/perf/index.html">Perf Analyzer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">sherpa-onnx</a> &raquo;</li>
          <li><a href="../index.html">Pre-trained models</a> &raquo;</li>
          <li><a href="index.html">Online transducer models</a> &raquo;</li>
      <li>Zipformer-transducer-based Models</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/pretrained_models/online-transducer/zipformer-transducer-models.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="zipformer-transducer-based-models">
<span id="sherpa-onnx-zipformer-transducer-models"></span><h1>Zipformer-transducer-based Models<a class="headerlink" href="#zipformer-transducer-based-models" title="Permalink to this headline"></a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Please refer to <a class="reference internal" href="../../install/index.html#install-sherpa-onnx"><span class="std std-ref">Installation</span></a> to install <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>
before you read this section.</p>
</div>
<section id="csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-02-21-english">
<h2>csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-02-21 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-02-21-english" title="Permalink to this headline"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/Zengwei/icefall-asr-librispeech-pruned-transducer-stateless7-streaming-2022-12-29">https://huggingface.co/Zengwei/icefall-asr-librispeech-pruned-transducer-stateless7-streaming-2022-12-29</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless7_streaming">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless7_streaming</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="download-the-model">
<h3>Download the model<a class="headerlink" href="#download-the-model" title="Permalink to this headline"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

<span class="nv">GIT_LFS_SKIP_SMUDGE</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-02-21
<span class="nb">cd</span><span class="w"> </span>sherpa-onnx-streaming-zipformer-en-2023-02-21
git<span class="w"> </span>lfs<span class="w"> </span>pull<span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;*.onnx&quot;</span>
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-streaming-zipformer-en-2023-02-21$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">1</span>.3M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">23</span>:06<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">2</span>.0M<span class="w"> </span>Feb<span class="w"> </span><span class="m">21</span><span class="w"> </span><span class="m">20</span>:51<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>180M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">23</span>:07<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>338M<span class="w"> </span>Feb<span class="w"> </span><span class="m">21</span><span class="w"> </span><span class="m">20</span>:51<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>254K<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">23</span>:06<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span>1003K<span class="w"> </span>Feb<span class="w"> </span><span class="m">21</span><span class="w"> </span><span class="m">20</span>:51<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="decode-a-single-wave-file">
<h3>Decode a single wave file<a class="headerlink" href="#decode-a-single-wave-file" title="Permalink to this headline"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="fp32">
<h4>fp32<a class="headerlink" href="#fp32" title="Permalink to this headline"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode a wave file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/joiner-epoch-99-avg-1.onnx&quot;, tokens=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/tokens.txt&quot;, num_threads=2, debug=False), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, decoding_method=&quot;greedy_search&quot;)
2023-04-01 06:16:29.128344485 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604840, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 06:16:29.128346568 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604841, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
sampling rate of input file: 16000
wav filename: ./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav
wav duration (s): 6.625
Started
Done!
Recognition result for ./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav:
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.825 s
Real time factor (RTF): 0.825 / 6.625 = 0.125
</pre></div>
</div>
</section>
<section id="int8">
<h4>int8<a class="headerlink" href="#int8" title="Permalink to this headline"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode a wave file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/decoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/decoder-epoch-99-avg-1.int8.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/joiner-epoch-99-avg-1.int8.onnx&quot;, tokens=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/tokens.txt&quot;, num_threads=2, debug=False), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, decoding_method=&quot;greedy_search&quot;)
2023-04-01 06:18:47.466564998 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604880, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 06:18:47.466566863 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604881, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
sampling rate of input file: 16000
wav filename: ./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav
wav duration (s): 6.625
Started
Done!
Recognition result for ./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav:
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.633 s
Real time factor (RTF): 0.633 / 6.625 = 0.096
</pre></div>
</div>
</section>
</section>
<section id="real-time-speech-recognition-from-a-microphone">
<h3>Real-time speech recognition from a microphone<a class="headerlink" href="#real-time-speech-recognition-from-a-microphone" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-en-2023-02-21/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If your system is Linux (including embedded Linux), you can also use
<a class="reference internal" href="../../install/aarch64-embedded-linux.html#sherpa-onnx-alsa"><span class="std std-ref">sherpa-onnx-alsa</span></a> to do real-time speech recognition with your
microphone if <code class="docutils literal notranslate"><span class="pre">sherpa-onnx-microphone</span></code> does not work for you.</p>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english">
<span id="sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20"></span><h2>csukuangfj/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20 (Bilingual, Chinese + English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english" title="Permalink to this headline"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/pfluo/k2fsa-zipformer-chinese-english-mixed">https://huggingface.co/pfluo/k2fsa-zipformer-chinese-english-mixed</a></p>
<p>which supports both Chinese and English. The model is contributed by the community
and is trained on tens of thousands of some internal dataset.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id1">
<h3>Download the model<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

<span class="nv">GIT_LFS_SKIP_SMUDGE</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/csukuangfj/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20
<span class="nb">cd</span><span class="w"> </span>sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20
git<span class="w"> </span>lfs<span class="w"> </span>pull<span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;*.onnx&quot;</span>
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>13M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">21</span>:11<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>14M<span class="w"> </span>Feb<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">20</span>:13<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span>174M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">21</span>:11<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span>315M<span class="w"> </span>Feb<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">20</span>:13<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span><span class="m">3</span>.1M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">21</span>:11<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>13M<span class="w"> </span>Feb<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">20</span>:13<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id2">
<h3>Decode a single wave file<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id3">
<h4>fp32<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode a wave file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/test_wavs/1.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/joiner-epoch-99-avg-1.onnx&quot;, tokens=&quot;./sherpa-onnx-streaming-zipformer-en-2023-02-21/tokens.txt&quot;, num_threads=2, debug=False), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, decoding_method=&quot;greedy_search&quot;)
2023-04-01 06:22:23.030317206 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604942, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 06:22:23.030315351 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604941, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
sampling rate of input file: 16000
wav filename: ./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav
wav duration (s): 6.625
Started
Done!
Recognition result for ./sherpa-onnx-streaming-zipformer-en-2023-02-21/test_wavs/0.wav:
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.815 s
Real time factor (RTF): 0.815 / 6.625 = 0.123
</pre></div>
</div>
</section>
<section id="id4">
<h4>int8<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode a wave file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/decoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/test_wavs/1.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/decoder-epoch-99-avg-1.int8.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/joiner-epoch-99-avg-1.int8.onnx&quot;, tokens=&quot;./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/tokens.txt&quot;, num_threads=2, debug=False), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, decoding_method=&quot;greedy_search&quot;)
2023-04-01 06:24:10.503505750 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604982, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 06:24:10.503503942 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 604981, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
sampling rate of input file: 16000
wav filename: ./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/test_wavs/1.wav
wav duration (s): 5.100
Started
Done!
Recognition result for ./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/test_wavs/1.wav:
这是第一种第二种叫呃与 ALWAYS ALWAYS什么意思啊
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.551 s
Real time factor (RTF): 0.551 / 5.100 = 0.108
</pre></div>
</div>
</section>
</section>
<section id="id5">
<h3>Real-time speech recognition from a microphone<a class="headerlink" href="#id5" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If your system is Linux (including embedded Linux), you can also use
<a class="reference internal" href="../../install/aarch64-embedded-linux.html#sherpa-onnx-alsa"><span class="std std-ref">sherpa-onnx-alsa</span></a> to do real-time speech recognition with your
microphone if <code class="docutils literal notranslate"><span class="pre">sherpa-onnx-microphone</span></code> does not work for you.</p>
</div>
</section>
</section>
<section id="shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french">
<span id="sherpa-onnx-streaming-zipformer-fr-2023-04-14"></span><h2>shaojieli/sherpa-onnx-streaming-zipformer-fr-2023-04-14 (French)<a class="headerlink" href="#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french" title="Permalink to this headline"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/shaojieli/icefall-asr-commonvoice-fr-pruned-transducer-stateless7-streaming-2023-04-02">https://huggingface.co/shaojieli/icefall-asr-commonvoice-fr-pruned-transducer-stateless7-streaming-2023-04-02</a></p>
<p>which supports only French as it is trained on the <a class="reference external" href="https://commonvoice.mozilla.org">CommonVoice</a> corpus.
In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id6">
<h3>Download the model<a class="headerlink" href="#id6" title="Permalink to this headline"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx
<span class="nv">GIT_LFS_SKIP_SMUDGE</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/shaojieli/sherpa-onnx-streaming-zipformer-fr-2023-04-14
<span class="nb">cd</span><span class="w"> </span>sherpa-onnx-streaming-zipformer-fr-2023-04-14
git<span class="w"> </span>lfs<span class="w"> </span>pull<span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;*.onnx&quot;</span>
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-streaming-zipformer-fr-2023-04-14<span class="w"> </span>shaojieli$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.bin

-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>lishaojie<span class="w"> </span>Students<span class="w">  </span><span class="m">1</span>.3M<span class="w"> </span>4月<span class="w">  </span><span class="m">14</span><span class="w"> </span><span class="m">14</span>:09<span class="w"> </span>decoder-epoch-29-avg-9-with-averaged-model.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>lishaojie<span class="w"> </span>Students<span class="w">  </span><span class="m">2</span>.0M<span class="w"> </span>4月<span class="w">  </span><span class="m">14</span><span class="w"> </span><span class="m">14</span>:09<span class="w"> </span>decoder-epoch-29-avg-9-with-averaged-model.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>lishaojie<span class="w"> </span>Students<span class="w">  </span>121M<span class="w"> </span>4月<span class="w">  </span><span class="m">14</span><span class="w"> </span><span class="m">14</span>:09<span class="w"> </span>encoder-epoch-29-avg-9-with-averaged-model.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>lishaojie<span class="w"> </span>Students<span class="w">  </span>279M<span class="w"> </span>4月<span class="w">  </span><span class="m">14</span><span class="w"> </span><span class="m">14</span>:09<span class="w"> </span>encoder-epoch-29-avg-9-with-averaged-model.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>lishaojie<span class="w"> </span>Students<span class="w">  </span>254K<span class="w"> </span>4月<span class="w">  </span><span class="m">14</span><span class="w"> </span><span class="m">14</span>:09<span class="w"> </span>joiner-epoch-29-avg-9-with-averaged-model.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>lishaojie<span class="w"> </span>Students<span class="w"> </span>1003K<span class="w"> </span>4月<span class="w">  </span><span class="m">14</span><span class="w"> </span><span class="m">14</span>:09<span class="w"> </span>joiner-epoch-29-avg-9-with-averaged-model.onnx
</pre></div>
</div>
</section>
<section id="id7">
<h3>Decode a single wave file<a class="headerlink" href="#id7" title="Permalink to this headline"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id8">
<h4>fp32<a class="headerlink" href="#id8" title="Permalink to this headline"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode a wave file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx
./build/bin/sherpa-onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/encoder-epoch-29-avg-9-with-averaged-model.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/decoder-epoch-29-avg-9-with-averaged-model.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/joiner-epoch-29-avg-9-with-averaged-model.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/test_wavs/common_voice_fr_19364697.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/encoder-epoch-29-avg-9-with-averaged-model.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/decoder-epoch-29-avg-9-with-averaged-model.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/joiner-epoch-29-avg-9-with-averaged-model.onnx&quot;, tokens=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/tokens.txt&quot;, num_threads=2, debug=False), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, decoding_method=&quot;greedy_search&quot;)
sampling rate of input file: 16000
wav filename: ./sherpa-onnx-streaming-zipformer-fr-2023-04-14/test_wavs/common_voice_fr_19364697.wav
wav duration (s): 7.128
Started
Done!
Recognition result for ./sherpa-onnx-streaming-zipformer-fr-2023-04-14/test_wavs/common_voice_fr_19364697.wav:
 CE SITE CONTIENT QUATRE TOMBEAUX DE LA DYNASTIE ASHÉMÉNIDE ET SEPT DES SASSANDIDES
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.458 s
Real time factor (RTF): 0.458 / 7.128 = 0.064
</pre></div>
</div>
</section>
<section id="id9">
<h4>int8<a class="headerlink" href="#id9" title="Permalink to this headline"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode a wave file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx
./build/bin/sherpa-onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/encoder-epoch-29-avg-9-with-averaged-model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/decoder-epoch-29-avg-9-with-averaged-model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/joiner-epoch-29-avg-9-with-averaged-model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/test_wavs/common_voice_fr_19364697.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/encoder-epoch-29-avg-9-with-averaged-model.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/decoder-epoch-29-avg-9-with-averaged-model.int8.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/joiner-epoch-29-avg-9-with-averaged-model.int8.onnx&quot;, tokens=&quot;./sherpa-onnx-streaming-zipformer-fr-2023-04-14/tokens.txt&quot;, num_threads=2, debug=False), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, decoding_method=&quot;greedy_search&quot;)
sampling rate of input file: 16000
wav filename: ./sherpa-onnx-streaming-zipformer-fr-2023-04-14/test_wavs/common_voice_fr_19364697.wav
wav duration (s): 7.128
Started
Done!
Recognition result for ./sherpa-onnx-streaming-zipformer-fr-2023-04-14/test_wavs/common_voice_fr_19364697.wav:
 CE SITE CONTIENT QUATRE TOMBEAUX DE LA DYNASTIE ASHÉMÉNIDE ET SEPT DES SASSANDIDES
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.485 s
Real time factor (RTF): 0.485 / 7.128 = 0.068
</pre></div>
</div>
</section>
</section>
<section id="id10">
<h3>Real-time speech recognition from a microphone<a class="headerlink" href="#id10" title="Permalink to this headline"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx
./build/bin/sherpa-onnx-microphone<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/encoder-epoch-29-avg-9-with-averaged-model.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/decoder-epoch-29-avg-9-with-averaged-model.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-streaming-zipformer-fr-2023-04-14/joiner-epoch-29-avg-9-with-averaged-model.onnx<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If your system is Linux (including embedded Linux), you can also use
<a class="reference internal" href="../../install/aarch64-embedded-linux.html#sherpa-onnx-alsa"><span class="std std-ref">sherpa-onnx-alsa</span></a> to do real-time speech recognition with your
microphone if <code class="docutils literal notranslate"><span class="pre">sherpa-onnx-microphone</span></code> does not work for you.</p>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Online transducer models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="conformer-transducer-models.html" class="btn btn-neutral float-right" title="Conformer-transducer-based Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>