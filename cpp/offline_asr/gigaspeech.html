<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Pretrained model with GigaSpeech &mdash; sherpa 1.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Pretrained model with WenetSpeech" href="wenetspeech.html" />
    <link rel="prev" title="C++ APIs" href="api.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">For Python users</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../python/huggingface/index.html">Try sherpa with Huggingface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/streaming_asr/index.html">Streaming ASR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/offline_asr/index.html">Non-streaming ASR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/faq.html">Frequently asked questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For C++ users</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pretrained_models/index.html">Pre-trained models</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Non-streaming ASR</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="api.html">C++ APIs</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Pretrained model with GigaSpeech</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#download-the-pretrained-model">Download the pretrained model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decode-a-single-wave">Decode a single wave</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decode-multiple-waves-in-parallel">Decode multiple waves in parallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decode-wav-scp">Decode wav.scp</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decode-feats-scp">Decode feats.scp</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="wenetspeech.html">Pretrained model with WenetSpeech</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../online_asr/index.html">Streaming ASR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">onnx</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../onnx/index.html">sherpa-onnx</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Non-streaming ASR</a> &raquo;</li>
      <li>Pretrained model with GigaSpeech</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/cpp/offline_asr/gigaspeech.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pretrained-model-with-gigaspeech">
<h1>Pretrained model with GigaSpeech<a class="headerlink" href="#pretrained-model-with-gigaspeech" title="Permalink to this headline"></a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>We assume you have installed <code class="docutils literal notranslate"><span class="pre">sherpa</span></code> by following
<a class="reference internal" href="../installation/index.html#cpp-fronted-installation"><span class="std std-ref">Installation</span></a> before you start this section.</p>
</div>
<section id="download-the-pretrained-model">
<h2>Download the pretrained model<a class="headerlink" href="#download-the-pretrained-model" title="Permalink to this headline"></a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo apt-get install git-lfs
git lfs install
git clone https://huggingface.co/wgb14/icefall-asr-gigaspeech-pruned-transducer-stateless2
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can find the training script by visiting
<a class="reference external" href="https://github.com/k2-fsa/icefall/blob/master/egs/gigaspeech/ASR/RESULTS.md#gigaspeech-bpe-training-results-pruned-transducer-2">https://github.com/k2-fsa/icefall/blob/master/egs/gigaspeech/ASR/RESULTS.md#gigaspeech-bpe-training-results-pruned-transducer-2</a></p>
<p>The torchscript model is exported using the script
<a class="reference external" href="https://github.com/k2-fsa/icefall/blob/master/egs/gigaspeech/ASR/pruned_transducer_stateless2/export.py">https://github.com/k2-fsa/icefall/blob/master/egs/gigaspeech/ASR/pruned_transducer_stateless2/export.py</a></p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>You have to use <a class="reference external" href="https://git-lfs.github.com/">git lfs</a> to download/clone the repo.
Otherwise, you will be SAD later.</p>
</div>
<p>After cloning the repo, you will find the following files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>icefall-asr-gigaspeech-pruned-transducer-stateless2/
|-- README.md
|-- data
|   `-- lang_bpe_500
|       `-- bpe.model
|-- exp
|   |-- cpu_jit-iter-3488000-avg-15.pt
|   |-- cpu_jit-iter-3488000-avg-20.pt
|   |-- pretrained-iter-3488000-avg-15.pt
|   `-- pretrained-iter-3488000-avg-20.pt
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data/lang_bpe_500/bpe.model</span></code> is the BPE model used in the training</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">exp/cpu_jit-iter-3488000-avg-15.pt</span></code> and <code class="docutils literal notranslate"><span class="pre">exp/cpu_jit-iter-3488000-avg-20.pt</span></code>
are two torchscript models exported using <code class="docutils literal notranslate"><span class="pre">torch.jit.script()</span></code>. We can use
any of them in the following tests.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We won’t use <code class="docutils literal notranslate"><span class="pre">pretrained-xxx.pt</span></code> in sherpa.</p>
</div>
<p>Before we start, let us generate <code class="docutils literal notranslate"><span class="pre">tokens.txt</span></code> from the above <code class="docutils literal notranslate"><span class="pre">bpe.model</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500
wget https://raw.githubusercontent.com/k2-fsa/sherpa/master/scripts/bpe_model_to_tokens.py
./bpe_model_to_tokens.py ./bpe.model &gt; tokens.txt
</pre></div>
</div>
<p>Since the above repo does not contain test waves, we download some
test files from <a class="reference external" href="https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless5-2022-05-13">https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless5-2022-05-13</a>.
for testing.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> icefall-asr-gigaspeech-pruned-transducer-stateless2
mkdir test_wavs
<span class="nb">cd</span> test_wavs

wget https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless5-2022-05-13/resolve/main/test_wavs/1089-134686-0001.wav

wget https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless5-2022-05-13/resolve/main/test_wavs/1221-135766-0001.wav

wget https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless5-2022-05-13/resolve/main/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<p>In the following, we show you how to use the downloaded model for speech
recognition.</p>
</section>
<section id="decode-a-single-wave">
<h2>Decode a single wave<a class="headerlink" href="#decode-a-single-wave" title="Permalink to this headline"></a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">nn_model</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt
<span class="nv">tokens</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt

<span class="nv">wav1</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1089-134686-0001.wav

sherpa <span class="se">\</span>
  --nn-model<span class="o">=</span><span class="nv">$nn_model</span> <span class="se">\</span>
  --tokens<span class="o">=</span><span class="nv">$tokens</span> <span class="se">\</span>
  --use-gpu<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nv">$wav1</span>
</pre></div>
</div>
<p>You will see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">miniconda</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">sherpa</span><span class="o">/</span><span class="n">conda</span><span class="o">-</span><span class="n">bld</span><span class="o">/</span><span class="n">sherpa_1661003501349</span><span class="o">/</span><span class="n">work</span><span class="o">/</span><span class="n">sherpa</span><span class="o">/</span><span class="n">csrc</span><span class="o">/</span><span class="n">parse_options</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">495</span><span class="p">:</span><span class="nb">int</span> <span class="n">sherpa</span><span class="p">::</span><span class="n">ParseOptions</span><span class="p">::</span><span class="n">Read</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">const</span> <span class="n">char</span><span class="o">*</span> <span class="n">const</span><span class="o">*</span><span class="p">)</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">20</span> <span class="mi">22</span><span class="p">:</span><span class="mi">35</span><span class="p">:</span><span class="mi">42</span> <span class="n">sherpa</span> <span class="o">--</span><span class="n">nn</span><span class="o">-</span><span class="n">model</span><span class="o">=./</span><span class="n">icefall</span><span class="o">-</span><span class="n">asr</span><span class="o">-</span><span class="n">gigaspeech</span><span class="o">-</span><span class="n">pruned</span><span class="o">-</span><span class="n">transducer</span><span class="o">-</span><span class="n">stateless2</span><span class="o">/</span><span class="n">exp</span><span class="o">/</span><span class="n">cpu_jit</span><span class="o">-</span><span class="nb">iter</span><span class="o">-</span><span class="mi">3488000</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">15.</span><span class="n">pt</span> <span class="o">--</span><span class="n">tokens</span><span class="o">=./</span><span class="n">icefall</span><span class="o">-</span><span class="n">asr</span><span class="o">-</span><span class="n">gigaspeech</span><span class="o">-</span><span class="n">pruned</span><span class="o">-</span><span class="n">transducer</span><span class="o">-</span><span class="n">stateless2</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">lang_bpe_500</span><span class="o">/</span><span class="n">tokens</span><span class="o">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">use</span><span class="o">-</span><span class="n">gpu</span><span class="o">=</span><span class="n">false</span> <span class="o">./</span><span class="n">icefall</span><span class="o">-</span><span class="n">asr</span><span class="o">-</span><span class="n">gigaspeech</span><span class="o">-</span><span class="n">pruned</span><span class="o">-</span><span class="n">transducer</span><span class="o">-</span><span class="n">stateless2</span><span class="o">/</span><span class="n">test_wavs</span><span class="o">/</span><span class="mi">1089</span><span class="o">-</span><span class="mi">134686</span><span class="o">-</span><span class="mf">0001.</span><span class="n">wav</span>

<span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">miniconda</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">sherpa</span><span class="o">/</span><span class="n">conda</span><span class="o">-</span><span class="n">bld</span><span class="o">/</span><span class="n">sherpa_1661003501349</span><span class="o">/</span><span class="n">work</span><span class="o">/</span><span class="n">sherpa</span><span class="o">/</span><span class="n">csrc</span><span class="o">/</span><span class="n">sherpa</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">126</span><span class="p">:</span><span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">char</span><span class="o">**</span><span class="p">)</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">20</span> <span class="mi">22</span><span class="p">:</span><span class="mi">35</span><span class="p">:</span><span class="mi">42</span>
<span class="o">--</span><span class="n">nn</span><span class="o">-</span><span class="n">model</span><span class="o">=./</span><span class="n">icefall</span><span class="o">-</span><span class="n">asr</span><span class="o">-</span><span class="n">gigaspeech</span><span class="o">-</span><span class="n">pruned</span><span class="o">-</span><span class="n">transducer</span><span class="o">-</span><span class="n">stateless2</span><span class="o">/</span><span class="n">exp</span><span class="o">/</span><span class="n">cpu_jit</span><span class="o">-</span><span class="nb">iter</span><span class="o">-</span><span class="mi">3488000</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">15.</span><span class="n">pt</span>
<span class="o">--</span><span class="n">tokens</span><span class="o">=./</span><span class="n">icefall</span><span class="o">-</span><span class="n">asr</span><span class="o">-</span><span class="n">gigaspeech</span><span class="o">-</span><span class="n">pruned</span><span class="o">-</span><span class="n">transducer</span><span class="o">-</span><span class="n">stateless2</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">lang_bpe_500</span><span class="o">/</span><span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
<span class="o">--</span><span class="n">decoding</span><span class="o">-</span><span class="n">method</span><span class="o">=</span><span class="n">greedy_search</span>
<span class="o">--</span><span class="n">use</span><span class="o">-</span><span class="n">gpu</span><span class="o">=</span><span class="n">false</span>

<span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">miniconda</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">sherpa</span><span class="o">/</span><span class="n">conda</span><span class="o">-</span><span class="n">bld</span><span class="o">/</span><span class="n">sherpa_1661003501349</span><span class="o">/</span><span class="n">work</span><span class="o">/</span><span class="n">sherpa</span><span class="o">/</span><span class="n">csrc</span><span class="o">/</span><span class="n">sherpa</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">270</span><span class="p">:</span><span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">char</span><span class="o">**</span><span class="p">)</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">20</span> <span class="mi">22</span><span class="p">:</span><span class="mi">35</span><span class="p">:</span><span class="mi">43</span>
<span class="n">filename</span><span class="p">:</span> <span class="o">./</span><span class="n">icefall</span><span class="o">-</span><span class="n">asr</span><span class="o">-</span><span class="n">gigaspeech</span><span class="o">-</span><span class="n">pruned</span><span class="o">-</span><span class="n">transducer</span><span class="o">-</span><span class="n">stateless2</span><span class="o">/</span><span class="n">test_wavs</span><span class="o">/</span><span class="mi">1089</span><span class="o">-</span><span class="mi">134686</span><span class="o">-</span><span class="mf">0001.</span><span class="n">wav</span>
<span class="n">result</span><span class="p">:</span>  <span class="n">AFTER</span> <span class="n">EARLY</span> <span class="n">NIGHTFALL</span> <span class="n">THE</span> <span class="n">YELLOW</span> <span class="n">LAMPS</span> <span class="n">WOULD</span> <span class="n">LIGHT</span> <span class="n">UP</span> <span class="n">HERE</span> <span class="n">AND</span> <span class="n">THERE</span> <span class="n">THE</span> <span class="n">SQUALID</span> <span class="n">QUARTER</span> <span class="n">OF</span> <span class="n">THE</span> <span class="n">BROTHELS</span>
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can pass the option <code class="docutils literal notranslate"><span class="pre">--use-gpu=true</span></code> to use GPU for computation (Assume
you have installed a CUDA version of <code class="docutils literal notranslate"><span class="pre">sherpa</span></code>).</p>
<p>Also, you can use <code class="docutils literal notranslate"><span class="pre">--decoding-method=modified_beam_search</span></code> to change
the decoding method.</p>
</div>
</section>
<section id="decode-multiple-waves-in-parallel">
<h2>Decode multiple waves in parallel<a class="headerlink" href="#decode-multiple-waves-in-parallel" title="Permalink to this headline"></a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">nn_model</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt
<span class="nv">tokens</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt

<span class="nv">wav1</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1089-134686-0001.wav
<span class="nv">wav2</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0001.wav
<span class="nv">wav3</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0002.wav

sherpa <span class="se">\</span>
  --nn-model<span class="o">=</span><span class="nv">$nn_model</span> <span class="se">\</span>
  --tokens<span class="o">=</span><span class="nv">$tokens</span> <span class="se">\</span>
  --use-gpu<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nv">$wav1</span> <span class="se">\</span>
  <span class="nv">$wav2</span> <span class="se">\</span>
  <span class="nv">$wav3</span>
</pre></div>
</div>
<p>You will see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>I<span class="o">]</span> /usr/share/miniconda/envs/sherpa/conda-bld/sherpa_1661003501349/work/sherpa/csrc/parse_options.cc:495:int sherpa::ParseOptions::Read<span class="o">(</span>int, const char* const*<span class="o">)</span> <span class="m">2022</span>-08-20 <span class="m">22</span>:38:18 sherpa --nn-model<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt --tokens<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt --use-gpu<span class="o">=</span><span class="nb">false</span> ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1089-134686-0001.wav ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0001.wav ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0002.wav

<span class="o">[</span>I<span class="o">]</span> /usr/share/miniconda/envs/sherpa/conda-bld/sherpa_1661003501349/work/sherpa/csrc/sherpa.cc:126:int main<span class="o">(</span>int, char**<span class="o">)</span> <span class="m">2022</span>-08-20 <span class="m">22</span>:38:19
--nn-model<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt
--tokens<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt
--decoding-method<span class="o">=</span>greedy_search
--use-gpu<span class="o">=</span><span class="nb">false</span>

<span class="o">[</span>I<span class="o">]</span> /usr/share/miniconda/envs/sherpa/conda-bld/sherpa_1661003501349/work/sherpa/csrc/sherpa.cc:284:int main<span class="o">(</span>int, char**<span class="o">)</span> <span class="m">2022</span>-08-20 <span class="m">22</span>:38:23
filename: ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1089-134686-0001.wav
result:  AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS

filename: ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0001.wav
result:  GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN

filename: ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0002.wav
result:  YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
</pre></div>
</div>
</section>
<section id="decode-wav-scp">
<h2>Decode wav.scp<a class="headerlink" href="#decode-wav-scp" title="Permalink to this headline"></a></h2>
<p>If you have some experience with <a class="reference external" href="https://github.com/kaldi-asr/kaldi">Kaldi</a>, you must know what <code class="docutils literal notranslate"><span class="pre">wav.scp</span></code> is.</p>
<p>We use the following code to generate <code class="docutils literal notranslate"><span class="pre">wav.scp</span></code> for our test data.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat &gt; wav.scp <span class="s">&lt;&lt;EOF</span>
<span class="s">wav1 ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1089-134686-0001.wav</span>
<span class="s">wav2 ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0001.wav</span>
<span class="s">wav3 ./icefall-asr-gigaspeech-pruned-transducer-stateless2/test_wavs/1221-135766-0002.wav</span>
<span class="s">EOF</span>
</pre></div>
</div>
<p>With the <code class="docutils literal notranslate"><span class="pre">wav.scp</span></code> ready, we can decode it with the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">nn_model</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt
<span class="nv">tokens</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt

sherpa <span class="se">\</span>
  --nn-model<span class="o">=</span><span class="nv">$nn_model</span> <span class="se">\</span>
  --tokens<span class="o">=</span><span class="nv">$tokens</span> <span class="se">\</span>
  --use-gpu<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  --use-wav-scp<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  scp:wav.scp <span class="se">\</span>
  ark,scp,t:results.ark,results.scp
</pre></div>
</div>
<p>You will see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>I<span class="o">]</span> /usr/share/miniconda/envs/sherpa/conda-bld/sherpa_1661003501349/work/sherpa/csrc/parse_options.cc:495:int sherpa::ParseOptions::Read<span class="o">(</span>int, const char* const*<span class="o">)</span> <span class="m">2022</span>-08-20 <span class="m">22</span>:40:36 sherpa --nn-model<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt --tokens<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt --use-gpu<span class="o">=</span><span class="nb">false</span> --use-wav-scp<span class="o">=</span><span class="nb">true</span> scp:wav.scp ark,scp,t:results.ark,results.scp

<span class="o">[</span>I<span class="o">]</span> /usr/share/miniconda/envs/sherpa/conda-bld/sherpa_1661003501349/work/sherpa/csrc/sherpa.cc:126:int main<span class="o">(</span>int, char**<span class="o">)</span> <span class="m">2022</span>-08-20 <span class="m">22</span>:40:37
--nn-model<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt
--tokens<span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt
--decoding-method<span class="o">=</span>greedy_search
--use-gpu<span class="o">=</span><span class="nb">false</span>
</pre></div>
</div>
<p>We can view the recognition results using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ cat results.ark

wav1 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
wav2 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
wav3 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can pass the option <code class="docutils literal notranslate"><span class="pre">--batch-size=20</span></code> to control the batch size to be 20
during decoding.</p>
</div>
</section>
<section id="decode-feats-scp">
<h2>Decode feats.scp<a class="headerlink" href="#decode-feats-scp" title="Permalink to this headline"></a></h2>
<p>If you have precomputed feats, you can decode it with the following code:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">nn_model</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/exp/cpu_jit-iter-3488000-avg-15.pt
<span class="nv">tokens</span><span class="o">=</span>./icefall-asr-gigaspeech-pruned-transducer-stateless2/data/lang_bpe_500/tokens.txt

sherpa <span class="se">\</span>
  --nn-model<span class="o">=</span><span class="nv">$nn_model</span> <span class="se">\</span>
  --tokens<span class="o">=</span><span class="nv">$tokens</span> <span class="se">\</span>
  --use-gpu<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  --use-feats-scp<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  scp:feats.scp <span class="se">\</span>
  ark,scp,t:results.ark,results.scp
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can pass the option <code class="docutils literal notranslate"><span class="pre">--batch-size=20</span></code> to control the batch size to be 20
during decoding.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p><code class="docutils literal notranslate"><span class="pre">feats.scp</span></code> generated by kaldi’s <code class="docutils literal notranslate"><span class="pre">compute-fbank-feats</span></code> is using
unnormalized samples. That is, audio samples are in the range
<code class="docutils literal notranslate"><span class="pre">[-32768,</span> <span class="pre">32767]</span></code>. However, models from <a class="reference external" href="https://github.com/k2-fsa/icefall">icefall</a> are trained with
features using normalized samples, i.e., samples in the range <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code>.</p>
<p>You cannot use <code class="docutils literal notranslate"><span class="pre">feats.scp</span></code> generated by Kaldi’s <code class="docutils literal notranslate"><span class="pre">compute-fbank-feats</span></code>
to test models trained from icefall using normalized audio samples.
Otherwise, you won’t get good recognition results.</p>
<p>It is perfectly OK to decode <code class="docutils literal notranslate"><span class="pre">feats.scp</span></code> from Kaldi using a model
trained with features using unnormalized audio samples.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We provide a script to generate <code class="docutils literal notranslate"><span class="pre">feats.ark</span></code> and <code class="docutils literal notranslate"><span class="pre">feats.scp</span></code> from
<code class="docutils literal notranslate"><span class="pre">wav.scp</span></code> that can be used with models trained by icefall. Please see
<a class="reference external" href="https://github.com/k2-fsa/sherpa/blob/master/.github/scripts/generate_feats_scp.py">https://github.com/k2-fsa/sherpa/blob/master/.github/scripts/generate_feats_scp.py</a></p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="api.html" class="btn btn-neutral float-left" title="C++ APIs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="wenetspeech.html" class="btn btn-neutral float-right" title="Pretrained model with WenetSpeech" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>