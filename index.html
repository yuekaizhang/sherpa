<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sherpa &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introduction" href="intro.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="#" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="onnx/index.html">sherpa-onnx</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
      <li>sherpa</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sherpa">
<h1>sherpa<a class="headerlink" href="#sherpa" title="Permalink to this heading"></a></h1>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="social-groups.html">Social groups</a><ul>
<li class="toctree-l2"><a class="reference internal" href="social-groups.html#wechat">WeChat</a></li>
<li class="toctree-l2"><a class="reference internal" href="social-groups.html#qq">QQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="social-groups.html#bilibili-b">Bilibili (B 站)</a></li>
<li class="toctree-l2"><a class="reference internal" href="social-groups.html#youtube">YouTube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="huggingface/index.html">Run Next-gen Kaldi in your browser</a><ul>
<li class="toctree-l2"><a class="reference internal" href="huggingface/index.html#visit-our-huggingface-space">Visit our Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="huggingface/index.html#youtube-video">YouTube Video</a></li>
<li class="toctree-l2"><a class="reference internal" href="huggingface/index.html#other-huggingface-spaces">Other Huggingface spaces</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pretrained-models.html">Pre-trained models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pretrained-models.html#pre-trained-models-for-different-projects">Pre-trained models for different projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="pretrained-models.html#how-to-download">How to download</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sherpa/index.html">sherpa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sherpa/install/index.html">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sherpa/install/from_wheels.html">From pre-compiled wheels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sherpa/install/from_wheels.html#linux-cpu">Linux (CPU)</a></li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/install/from_wheels.html#macos-cpu">macOS (CPU)</a></li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/install/from_wheels.html#linux-cuda">Linux (CUDA)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sherpa/install/from_source.html">From source</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sherpa/install/from_source.html#install-dependencies">Install dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/install/from_source.html#for-general-users">For general users</a></li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/install/from_source.html#for-developers-and-advanced-users">For developers and advanced users</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sherpa/install/check_your_installation.html">Check your installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="sherpa/install/index.html#where-to-get-help">Where to get help</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sherpa/pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/index.html">Offline CTC models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html">icefall</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html#icefall-asr-gigaspeech-conformer-ctc-english">icefall-asr-gigaspeech-conformer-ctc (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html#icefall-asr-librispeech-conformer-ctc-jit-bpe-500-2021-11-09-english">icefall-asr-librispeech-conformer-ctc-jit-bpe-500-2021-11-09 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html#icefall-asr-tedlium3-conformer-ctc2-english">icefall-asr-tedlium3-conformer-ctc2 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html#icefall-asr-librispeech-conformer-ctc-english">icefall_asr_librispeech_conformer_ctc (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html#icefall-asr-aishell-conformer-ctc-chinese">icefall_asr_aishell_conformer_ctc (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/icefall.html#icefall-asr-mgb2-conformer-ctc-2022-27-06-arabic">icefall-asr-mgb2-conformer_ctc-2022-27-06 (Arabic)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/wenet.html">WeNet</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/wenet.html#wenet-english-model-english">wenet-english-model (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/wenet.html#wenet-chinese-model-chinese">wenet-chinese-model (Chinese)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/torchaudio.html">torchaudio</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/torchaudio.html#wav2vec2-asr-base-english">wav2vec2_asr_base (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/torchaudio.html#voxpopuli-asr-base-german">voxpopuli_asr_base (German)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html">NeMo</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-en-citrinet-512-english">sherpa-nemo-ctc-en-citrinet-512 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-zh-citrinet-512-chinese">sherpa-nemo-ctc-zh-citrinet-512 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-zh-citrinet-1024-gamma-0-25-chinese">sherpa-nemo-ctc-zh-citrinet-1024-gamma-0-25 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-de-citrinet-1024-german">sherpa-nemo-ctc-de-citrinet-1024 (German)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-en-conformer-small-english">sherpa-nemo-ctc-en-conformer-small (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-en-conformer-medium-english">sherpa-nemo-ctc-en-conformer-medium (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-en-conformer-large-english">sherpa-nemo-ctc-en-conformer-large (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#sherpa-nemo-ctc-de-conformer-large-german">sherpa-nemo-ctc-de-conformer-large (German)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_ctc/nemo.html#how-to-convert-nemo-models-to-sherpa">How to convert NeMo models to sherpa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sherpa/pretrained_models/offline_transducer.html">Offline transducer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sherpa/pretrained_models/offline_transducer.html#icefall">icefall</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_transducer.html#english">English</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_transducer.html#chinese">Chinese</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_transducer.html#chinese-english">Chinese + English</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/offline_transducer.html#tibetan">Tibetan</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sherpa/pretrained_models/online_transducer.html">Online transducer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sherpa/pretrained_models/online_transducer.html#icefall">icefall</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/online_transducer.html#english">English</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/online_transducer.html#chinese">Chinese</a></li>
<li class="toctree-l5"><a class="reference internal" href="sherpa/pretrained_models/online_transducer.html#chinese-english-all-in-one">Chinese + English (all-in-one)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ncnn/index.html">sherpa-ncnn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ncnn/tutorials/index.html">Tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/tutorials/cn.html">中文资料 (Chinese tutorials)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#sherpa-ncnn-windows">Sherpa-ncnn (Windows電腦抓取麥克風聲音即時轉錄文字)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#androidsherpancnn">2024 Android整合SherpaNcnn实现离线语音识别（支持中文，手把手带你从编译动态库开始）</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#unity-sherpa-ncnn">2024 在Unity环境下，借助sherpa-ncnn框架，实现实时并准确的中英双语语音识别功能</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#rv1126sherpatts">2024-02-22【RV1126】移植sherpa实时语音识别和TTS文字转语音功能</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#sherpa-ncnn">2023-12-31 离线语音识别 sherpa-ncnn 尝鲜体验</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#rv1126kaldi">2023-04-26【RV1126】移植kaldi实时语音识别</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/tutorials/cn.html#id1">2023-02-19 离线语音识别库sherpa-ncnn安装和简单测试笔记</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/install/index.html">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/videos.html">Installation videos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/videos.html#window-64-bit">Window (64-bit)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/linux.html">Linux</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/macos.html">macOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/windows.html">Windows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/windows.html#bit-windows-x64">64-bit Windows (x64)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/windows.html#bit-windows-x86">32-bit Windows (x86)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/arm-embedded-linux.html">Embedded Linux (arm)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/arm-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/arm-embedded-linux.html#build-sherpa-ncnn">Build sherpa-ncnn</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/aarch64-embedded-linux.html">Embedded Linux (aarch64)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/aarch64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/aarch64-embedded-linux.html#build-sherpa-ncnn">Build sherpa-ncnn</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/aarch64-embedded-linux.html#sherpa-ncnn-alsa">sherpa-ncnn-alsa</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/install/riscv64-embedded-linux.html">Embedded Linux (riscv64)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/riscv64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/install/riscv64-embedded-linux.html#build-sherpa-ncnn">Build sherpa-ncnn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/python/index.html">Python API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/python/index.html#installation">Installation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#method-1">Method 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#method-2">Method 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#method-3">Method 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#method-4-for-developers-and-embedded-boards">Method 4 (For developers and embedded boards)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/python/index.html#real-time-recognition-with-a-microphone">Real-time recognition with a microphone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#import-the-required-packages">1. Import the required packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#create-the-recognizer">2. Create the recognizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#start-recording">3. Start recording</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#read-audio-samples-from-the-microphone">4. Read audio samples from the microphone</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#invoke-the-recognizer-with-audio-samples">5. Invoke the recognizer with audio samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#get-the-recognition-result">6. Get the recognition result</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/python/index.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/python/index.html#recognize-a-file">Recognize a file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/wasm/index.html">WebAssembly</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/wasm/install-emscripten.html">Install Emscripten</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/wasm/build.html">Build</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/wasm/prebuilt.html">Use pre-built WebAssembly library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/wasm/prebuilt.html#download">Download</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/wasm/hf-spaces.html">Huggingface Spaces (WebAssembly)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/wasm/hf-spaces.html#english-only">English only</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/wasm/hf-spaces.html#chinese-english">Chinese + English</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/c-api/index.html">C API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/c-api/index.html#generate-required-files">Generate required files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/c-api/index.html#build-shared-libraries">Build shared libraries</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/c-api/index.html#build-static-libraries">Build static libraries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/c-api/index.html#build-decode-file-c-api-c-with-generated-files">Build decode-file-c-api.c with generated files</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/endpoint.html">Endpointing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/endpoint.html#rule-1">Rule 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/endpoint.html#rule-2">Rule 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/endpoint.html#rule-3">Rule 3</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/endpoint.html#demo">Demo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/endpoint.html#multilingual-chinese-english">Multilingual (Chinese + English)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/endpoint.html#faqs">FAQs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/endpoint.html#how-to-compute-duration-of-silence">How to compute duration of silence</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/android/index.html">Android</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/android/demo-videos.html">Video demos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/demo-videos.html#video-1-chinese">Video 1: Chinese</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/demo-videos.html#video-2-chinese-english">Video 2: Chinese + English</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/demo-videos.html#video-3-chinese-with-background-noise">Video 3: Chinese with background noise</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/demo-videos.html#video-4-chinese-poem-with-background-music">Video 4: Chinese poem with background music</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html">Build sherpa-ncnn for Android</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#install-android-studio">Install Android Studio</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#download-sherpa-ncnn">Download sherpa-ncnn</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#install-ndk">Install NDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#build-sherpa-ncnn-c-code">Build sherpa-ncnn (C++ code)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#build-for-arm64-v8a">Build for arm64-v8a</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#build-for-armeabi-v7a">Build for armeabi-v7a</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#build-for-x86-64">Build for x86_64</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#build-for-x86">Build for x86</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#download-pre-trained-models">Download pre-trained models</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#generate-apk">Generate APK</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/android/build-sherpa-ncnn.html#analyze-the-apk">Analyze the APK</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/ios/index.html">iOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/ios/demo-videos.html">Video demos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/demo-videos.html#video-1-chinese-english-on-iphone-14-pro-simulator">Video 1: Chinese + English on iPhone 14 Pro (simulator)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/demo-videos.html#video-2-chinese-english-on-ipad-11-pro-simulator">Video 2: Chinese + English on iPad 11 Pro (simulator)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/ios/build-sherpa-ncnn-swift.html">Build sherpa-ncnn for iOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/build-sherpa-ncnn-swift.html#requirement">Requirement</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/build-sherpa-ncnn-swift.html#download-sherpa-ncnn">Download sherpa-ncnn</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/build-sherpa-ncnn-swift.html#build-sherpa-ncnn-in-commandline-c-part">Build sherpa-ncnn (in commandline, C++ Part)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/build-sherpa-ncnn-swift.html#build-sherpa-ncnn-in-xcode">Build sherpa-ncnn (in Xcode)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/build-sherpa-ncnn-swift.html#run-sherpa-ncnn-on-your-iphone-ipad">Run sherpa-ncnn on your iPhone/iPad</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/ios/for-the-more-curious-swift.html">For the more curious</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/for-the-more-curious-swift.html#files-generated-by-running-build-ios-sh">Files generated by running ./build-ios.sh</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/ios/for-the-more-curious-swift.html#openmp-xcframework">openmp.xcframework</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/ios/for-the-more-curious-swift.html#sherpa-ncnn-xcframework">sherpa-ncnn.xcframework</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/ios/for-the-more-curious-swift.html#how-to-use-files-generated-by-build-ios-sh-in-xcode">How to use files generated by ./build-ios.sh in Xcode</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/pretrained_models/small-models.html">Small models</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#marcoyang-sherpa-ncnn-streaming-zipformer-zh-14m-2023-02-23-chinese">marcoyang/sherpa-ncnn-streaming-zipformer-zh-14M-2023-02-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#marcoyang-sherpa-ncnn-streaming-zipformer-20m-2023-02-17-english">marcoyang/sherpa-ncnn-streaming-zipformer-20M-2023-02-17 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id2">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id3">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id4">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#csukuangfj-sherpa-ncnn-streaming-zipformer-en-2023-02-13-english">csukuangfj/sherpa-ncnn-streaming-zipformer-en-2023-02-13 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id7">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id8">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#csukuangfj-sherpa-ncnn-streaming-zipformer-bilingual-zh-en-2023-02-13-bilingual-chinese-english">csukuangfj/sherpa-ncnn-streaming-zipformer-bilingual-zh-en-2023-02-13 (Bilingual, Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id9">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id10">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id11">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#csukuangfj-sherpa-ncnn-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english">csukuangfj/sherpa-ncnn-streaming-zipformer-small-bilingual-zh-en-2023-02-16 (Bilingual, Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id12">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id13">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id14">Real-time speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#a-faster-model-of-sherpa-ncnn-streaming-zipformer-small-bilingual-zh-en-2023-02-16">A faster model of sherpa-ncnn-streaming-zipformer-small-bilingual-zh-en-2023-02-16</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#shaojieli-sherpa-ncnn-streaming-zipformer-fr-2023-04-14">shaojieli/sherpa-ncnn-streaming-zipformer-fr-2023-04-14</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id15">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/zipformer-transucer-models.html#id16">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/pretrained_models/lstm-transducer-models.html">LSTM-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/lstm-transducer-models.html#marcoyang-sherpa-ncnn-lstm-transducer-small-2023-02-13-bilingual-chinese-english">marcoyang/sherpa-ncnn-lstm-transducer-small-2023-02-13 (Bilingual, Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/lstm-transducer-models.html#decode-a-single-wave-file-with-build-bin-sherpa-ncnn">Decode a single wave file with ./build/bin/sherpa-ncnn</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/lstm-transducer-models.html#csukuangfj-sherpa-ncnn-2022-09-05-english">csukuangfj/sherpa-ncnn-2022-09-05 (English)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/lstm-transducer-models.html#csukuangfj-sherpa-ncnn-2022-09-30-chinese">csukuangfj/sherpa-ncnn-2022-09-30 (Chinese)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html">Conv-Emformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#marcoyang-sherpa-ncnn-conv-emformer-transducer-small-2023-01-09-english">marcoyang/sherpa-ncnn-conv-emformer-transducer-small-2023-01-09 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#decode-a-single-wave-file-with-build-bin-sherpa-ncnn">Decode a single wave file with ./build/bin/sherpa-ncnn</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#decode-a-single-wave-file-with-build-bin-sherpa-ncnn-with-int8-quantization">Decode a single wave file with ./build/bin/sherpa-ncnn (with int8 quantization)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#csukuangfj-sherpa-ncnn-conv-emformer-transducer-2022-12-06-chinese-english">csukuangfj/sherpa-ncnn-conv-emformer-transducer-2022-12-06 (Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#id3">Decode a single wave file with ./build/bin/sherpa-ncnn</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#real-time-speech-recognition-from-a-microphone-with-build-bin-sherpa-ncnn-microphone">Real-time speech recognition from a microphone with build/bin/sherpa-ncnn-microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#csukuangfj-sherpa-ncnn-conv-emformer-transducer-2022-12-08-chinese">csukuangfj/sherpa-ncnn-conv-emformer-transducer-2022-12-08 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#id4">Decode a single wave file with ./build/bin/sherpa-ncnn</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#id5">Real-time speech recognition from a microphone with build/bin/sherpa-ncnn-microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#csukuangfj-sherpa-ncnn-conv-emformer-transducer-2022-12-04-english">csukuangfj/sherpa-ncnn-conv-emformer-transducer-2022-12-04 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#id6">Decode a single wave file with ./build/bin/sherpa-ncnn</a></li>
<li class="toctree-l5"><a class="reference internal" href="ncnn/pretrained_models/conv-emformer-transducer-models.html#id7">Real-time speech recognition from a microphone with build/bin/sherpa-ncnn-microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/examples/index.html">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html">Raspberry Pi 3B E14</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html#board-info">Board info</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html#os-release">OS release</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html#lscpu">lscpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html#cpuinfo">cpuinfo</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html#rtf-1-thread">RTF (1 thread)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/raspberry-pi-3.html#rtf-2-threads">RTF (2 threads)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/examples/jetson-nano.html">Jetson Nano</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/jetson-nano.html#board-info">Board info</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/jetson-nano.html#rtf-4-threads">RTF (4 threads)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/examples/jetson-nx.html">Jetson NX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/jetson-nx.html#board-info">Board info</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/jetson-nx.html#rtf-2-threads">RTF (2 threads)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/jetson-nx.html#rtf-4-threads">RTF (4 threads)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/jetson-nx.html#rtf-6-threads">RTF (6 threads)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/examples/vision-five-2.html">VisionFive 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/vision-five-2.html#board-info">Board info</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/vision-five-2.html#rtf-4-threads">RTF (4 threads)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ncnn/examples/vision-five-2.html#real-time-speech-recognition-with-a-microphone">Real-time speech recognition with a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ncnn/faq.html">FAQs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ncnn/faq.html#where-to-get-help">Where to get help</a></li>
<li class="toctree-l3"><a class="reference internal" href="ncnn/faq.html#no-default-input-device-found">No default input device found</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="onnx/index.html">sherpa-onnx</a><ul>
<li class="toctree-l2"><a class="reference internal" href="onnx/tutorials/index.html">Tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/tutorials/cn.html">中文资料 (Chinese tutorials)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#sherpa-onnx-cpu-docker">2024-07-03【🆓 語音辨識引擎sherpa-onnx CPU上篇】讓您輕鬆體驗語音辨識功能(Docker架設)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#sherpaonnxttsengine-android-tts">2024-06-10 SherpaOnnxTtsEngine - Android 本地 TTS 语言转文本引擎</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#llm100-01windows-1">2024-06-10 用LLM搭建100个应用（一）：从0到1搭建自己的Windows贾维斯(1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#sherpa-onnx">2024-05-09 记录一下sherpa-onnx的安装及使用</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#rv1106-rv1109-rv1126sherpa-onnx-tts">2024-04-09 rv1106&amp;rv1109&amp;rv1126移植sherpa-onnx 实现离线TTS功能</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#snowboy-kaldi-k2-fsa-sherpa-onnx">2023-08-08 snowboy+新一代kaldi（k2-fsa）sherpa-onnx实现离线语音识别【语音助手】</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tutorials/cn.html#k2-sherpa-onnx">2023-03-16 k2语音识别：如何使用sherpa-onnx</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/install/index.html">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/install/linux.html">Linux</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/install/macos.html">macOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/install/windows.html">Windows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/windows.html#bit-windows-x64">64-bit Windows (x64)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/windows.html#bit-windows-x86">32-bit Windows (x86)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/install/aarch64-embedded-linux.html">Embedded Linux (aarch64)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/aarch64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/aarch64-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/aarch64-embedded-linux.html#sherpa-onnx-alsa">sherpa-onnx-alsa</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/aarch64-embedded-linux.html#how-to-build-static-libraries-and-static-linked-binaries">How to build static libraries and static linked binaries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/install/arm-embedded-linux.html">Embedded Linux (arm)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/arm-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/arm-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/arm-embedded-linux.html#how-to-build-static-libraries-and-static-linked-binaries">How to build static libraries and static linked binaries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/install/riscv64-embedded-linux.html">Embedded Linux (riscv64)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/riscv64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/riscv64-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/install/riscv64-embedded-linux.html#qemu">qemu</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/install/riscv64-embedded-linux.html#run-speech-to-text-with-qemu">Run speech-to-text with qemu</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/install/riscv64-embedded-linux.html#run-text-to-speech-with-qemu">Run text-to-speech with qemu</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/faqs/index.html">Frequently Asked Question (FAQs)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/faqs/index.html#id1">在线、离线、流式、非流式的区别</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/faqs/index.html#cannot-open-shared-library-libasound-module-conf-pulse-so">Cannot open shared library libasound_module_conf_pulse.so</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/faqs/index.html#tts">TTS 中文模型没有声音</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/faqs/index.html#gitcompile-line-89-libtoolize-command-not-found">./gitcompile: line 89: libtoolize: command not found</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/faqs/index.html#oserror-portaudio-library-not-found">OSError: PortAudio library not found</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/faqs/index.html#imports-github-com-k2-fsa-sherpa-onnx-go-linux-build-constraints-exclude-all-go-files">imports github.com/k2-fsa/sherpa-onnx-go-linux: build constraints exclude all Go files</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/python/index.html">Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/python/install.html">Install the Python Package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/install.html#method-1-from-pre-compiled-wheels-cpu-only">Method 1 (From pre-compiled wheels, CPU only)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/install.html#method-2-from-pre-compiled-wheels-cpu-cuda">Method 2 (From pre-compiled wheels, CPU + CUDA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/install.html#method-3-from-source">Method 3 (From source)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/install.html#method-4-for-developers">Method 4 (For developers)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/install.html#check-your-installation">Check your installation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/python/decode-files.html">Decode files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/decode-files.html#streaming-zipformer">Streaming zipformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/decode-files.html#non-streaming-zipformer">Non-streaming zipformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/decode-files.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/python/real-time-speech-recongition-from-a-microphone.html">Real-time speech recognition from a microphone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/real-time-speech-recongition-from-a-microphone.html#with-endpoint-detection">With endpoint detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/real-time-speech-recongition-from-a-microphone.html#without-endpoint-detection">Without endpoint detection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html">Speech recognition from URLs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html#decode-a-url">Decode a URL</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html#rtmp">RTMP</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html#install-the-server">Install the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html#start-the-server">Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html#start-ffmpeg-to-push-audio-stream">Start ffmpeg to push audio stream</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/speech-recognition-from-urls.html#start-sherpa-onnx-to-pull-audio-stream">Start sherpa-onnx to pull audio stream</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/python/streaming-websocket-server.html">Streaming WebSocket Server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/streaming-websocket-server.html#start-the-server">Start the server</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/streaming-websocket-server.html#use-python-api">Use Python API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/streaming-websocket-server.html#use-a-browser">Use a browser</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/streaming-websocket-server.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html">Non-Streaming WebSocket Server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#non-streaming-transducer">Non-streaming transducer</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#start-the-server">Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#start-the-client">Start the client</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#non-streaming-paraformer">Non-streaming paraformer</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#id1">Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#id2">Start the client</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#non-streaming-ctc-model-from-nemo">Non-streaming CTC model from NeMo</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#id3">Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#id4">Start the client</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#non-streaming-whisper-tiny-en">Non-streaming Whisper tiny.en</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#id5">Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#id6">Start the client</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/python/non-streaming-websocket-server.html#colab">colab</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/c-api/index.html">C API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/c-api/index.html#generate-required-files">Generate required files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/c-api/index.html#build-shared-libraries">Build shared libraries</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/c-api/index.html#build-static-libraries">Build static libraries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/c-api/index.html#build-decode-file-c-api-c-with-generated-files">Build decode-file-c-api.c with generated files</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/c-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/java-api/index.html">Java API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/java-api/build-jni-macos.html">Build JNI interface (macOS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-macos.html#setup-the-environment">Setup the environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-macos.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-macos.html#download-pre-built-jni-libs">Download pre-built JNI libs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/java-api/build-jni-linux.html">Build JNI interface (Linux)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-linux.html#setup-the-environment">Setup the environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-linux.html#download-pre-built-jni-libs">Download pre-built JNI libs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/java-api/build-jni-windows.html">Build JNI interface (Windows)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jni-windows.html#download-pre-built-jni-libs">Download pre-built JNI libs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/java-api/build-jar.html">Build the jar package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/java-api/build-jar.html#download-pre-built-jar">Download pre-built jar</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/java-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/javascript-api/index.html">Javascript API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/javascript-api/install.html">Install</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/javascript-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/kotlin-api/index.html">Kotlin API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/kotlin-api/build-jni.html">Build JNI interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/kotlin-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/swift-api/index.html">Swift API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/swift-api/build.html">Build</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/swift-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/go-api/index.html">Go API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/go-api/index.html#decode-files-with-non-streaming-models">Decode files with non-streaming models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/go-api/index.html#non-streaming-transducer">Non-streaming transducer</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/go-api/index.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/go-api/index.html#non-streaming-ctc-model-from-nemo">Non-streaming CTC model from NeMo</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/go-api/index.html#decode-files-with-streaming-models">Decode files with streaming models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/go-api/index.html#streaming-transducer">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/go-api/index.html#real-time-speech-recognition-from-microphone">Real-time speech recognition from microphone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/go-api/index.html#id3">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/go-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/csharp-api/index.html">C# API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/csharp-api/index.html#decode-files-with-non-streaming-models">Decode files with non-streaming models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/csharp-api/index.html#non-streaming-transducer">Non-streaming transducer</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/csharp-api/index.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/csharp-api/index.html#non-streaming-ctc-model-from-nemo">Non-streaming CTC model from NeMo</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/csharp-api/index.html#decode-files-with-streaming-models">Decode files with streaming models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/csharp-api/index.html#streaming-transducer">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/csharp-api/index.html#real-time-speech-recognition-from-microphone">Real-time speech recognition from microphone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/csharp-api/index.html#id1">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/csharp-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/pascal-api/index.html">Pascal API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/pascal-api/index.html#install-free-pascal">Install free pascal</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pascal-api/index.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pascal-api/index.html#non-streaming-speech-recognition-from-files">Non-streaming speech recognition from files</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pascal-api/index.html#colab-notebook">Colab notebook</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/lazarus/index.html">Lazarus</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/lazarus/pre-built-app.html">Pre-built APPs using Lazarus</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html">Generate subtitles</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#screenshots-on-different-platforms">Screenshots on different platforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#get-sherpa-onnx-libraries">Get sherpa-onnx libraries</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#build-sherpa-onnx-from-source">1. Build sherpa-onnx from source</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#download-pre-built-libraries">2. Download pre-built libraries</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#build-the-generate-subtitles-project">Build the generate_subtitles project</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#download-models">Download models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#download-the-vad-model">Download the VAD model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#download-a-speech-recognition-model">Download a speech recognition model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#wisper">1. Wisper</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#zipformer-transducer">2. Zipformer transducer</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#nemo-transducer">3. NeMo transducer</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#sensevoice">4. SenseVoice</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#paraformer">5. Paraformer</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#telespeech">6. TeleSpeech</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/lazarus/generate-subtitles.html#for-the-more-curious">For the more curious</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/wasm/index.html">WebAssembly</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/wasm/install-emscripten.html">Install Emscripten</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/wasm/build.html">Build</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/wasm/hf-spaces.html">Huggingface Spaces (WebAssembly)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/wasm/hf-spaces.html#english-only-zipformer">English only (Zipformer)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/wasm/hf-spaces.html#chinese-english-zipformer">Chinese + English (Zipformer)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/wasm/hf-spaces.html#chinese-english-paraformer">Chinese + English (Paraformer)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/wasm/hf-spaces.html#chinese-english-cantonese-paraformer">Chinese + English + Cantonese (Paraformer)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/android/index.html">Android</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/android/prebuilt-apk.html">Pre-built APKs</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html">Build sherpa-onnx for Android</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#install-android-studio">Install Android Studio</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#download-sherpa-onnx">Download sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#install-ndk">Install NDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#build-sherpa-onnx-c-code">Build sherpa-onnx (C++ code)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#build-for-arm64-v8a">Build for arm64-v8a</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#build-for-armv7-eabi">Build for armv7-eabi</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#build-for-x86-64">Build for x86_64</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#build-for-x86">Build for x86</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#download-pre-trained-models">Download pre-trained models</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#generate-apk">Generate APK</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/android/build-sherpa-onnx.html#analyze-the-apk">Analyze the APK</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/ios/index.html">iOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/ios/build-sherpa-onnx-swift.html">Build sherpa-onnx for iOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/ios/build-sherpa-onnx-swift.html#requirement">Requirement</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/ios/build-sherpa-onnx-swift.html#download-sherpa-onnx">Download sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/ios/build-sherpa-onnx-swift.html#build-sherpa-onnx-in-commandline-c-part">Build sherpa-onnx (in commandline, C++ Part)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/ios/build-sherpa-onnx-swift.html#build-sherpa-onnx-in-xcode">Build sherpa-onnx (in Xcode)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/ios/build-sherpa-onnx-swift.html#run-sherpa-onnx-on-your-iphone-ipad">Run sherpa-onnx on your iPhone/iPad</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/flutter/index.html">Flutter</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/flutter/pre-built-app.html">Pre-built Flutter Apps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/flutter/pre-built-app.html#text-to-speech-tts-speech-synthesis">Text to speech (TTS, Speech synthesis)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/flutter/pre-built-app.html#streaming-speech-recognition-stt-asr">Streaming Speech recognition (STT, ASR)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/websocket/index.html">WebSocket</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/websocket/online-websocket.html">Streaming WebSocket server and client</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#build-sherpa-onnx-with-websocket-support">Build <cite>sherpa-onnx</cite> with WebSocket support</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#view-the-server-usage">View the server usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#start-the-server">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#view-the-usage-of-the-client-c">View the usage of the client (C++)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#start-the-client-c">Start the client (C++)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#view-the-usage-of-the-client-python">View the usage of the client (Python)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#start-the-client-python">Start the client (Python)</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/online-websocket.html#start-the-client-python-with-microphone">Start the client (Python, with microphone)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/websocket/offline-websocket.html">Non-streaming WebSocket server and client</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/offline-websocket.html#build-sherpa-onnx-with-websocket-support">Build <cite>sherpa-onnx</cite> with WebSocket support</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/offline-websocket.html#view-the-server-usage">View the server usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/offline-websocket.html#start-the-server">Start the server</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/websocket/offline-websocket.html#start-the-server-with-a-transducer-model">Start the server with a transducer model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/websocket/offline-websocket.html#start-the-server-with-a-paraformer-model">Start the server with a paraformer model</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/websocket/offline-websocket.html#start-the-client-python">Start the client (Python)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/websocket/offline-websocket.html#id1">offline-websocket-client-decode-files-paralell.py</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/websocket/offline-websocket.html#id2">offline-websocket-client-decode-files-sequential.py</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/hotwords/index.html">Hotwords (Contextual biasing)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/hotwords/index.html#what-are-hotwords">What are hotwords</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/hotwords/index.html#how-do-we-implement-it-with-an-aho-corasick">How do we implement it with an Aho-corasick</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/hotwords/index.html#how-to-use-hotwords-in-sherpa-onnx">How to use hotwords in sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/hotwords/index.html#modeling-unit-is-bpe">Modeling unit is bpe</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/hotwords/index.html#c-api">C++ api</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/hotwords/index.html#python-api">Python api</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/hotwords/index.html#modeling-unit-is-cjkchar">Modeling unit is cjkchar</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/hotwords/index.html#id1">C++ api</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/hotwords/index.html#id2">Python api</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/hotwords/index.html#modeling-unit-is-cjkchar-bpe">Modeling unit is cjkchar+bpe</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/hotwords/index.html#id3">C++ api</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/hotwords/index.html#id4">Python api</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/kws/index.html">Keyword spotting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/kws/index.html#what-is-open-vocabulary-keyword-spotting">What is open vocabulary keyword spotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/kws/index.html#decoder-for-open-vocabulary-keyword-spotting">Decoder for open vocabulary keyword spotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/kws/index.html#keywords-file">Keywords file</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/kws/index.html#how-to-use-keyword-spotting-in-sherpa-onnx">How to use keyword spotting in sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/kws/index.html#command-line-tool">command-line tool</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/kws/index.html#android-application">Android application</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/kws/index.html#pretrained-models">Pretrained models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/punctuation/index.html">Punctuation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/punctuation/pretrained_models.html">Pre-trained models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/punctuation/pretrained_models.html#sherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12">sherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/punctuation/pretrained_models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/punctuation/pretrained_models.html#c-binary-examples">C++ binary examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/punctuation/pretrained_models.html#python-api-examples">Python API examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/punctuation/pretrained_models.html#huggingface-space-examples">Huggingface space examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/punctuation/pretrained_models.html#video-demos">Video demos</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/audio-tagging/index.html">Audio tagging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/audio-tagging/pretrained_models.html">Pre-trained models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/audio-tagging/pretrained_models.html#sherpa-onnx-zipformer-small-audio-tagging-2024-04-15">sherpa-onnx-zipformer-small-audio-tagging-2024-04-15</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/audio-tagging/pretrained_models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/audio-tagging/pretrained_models.html#c-binary-examples">C++ binary examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/audio-tagging/pretrained_models.html#python-api-examples">Python API examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/audio-tagging/pretrained_models.html#huggingface-space">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/audio-tagging/android.html">Android</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/audio-tagging/wearos.html">WearOS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/spoken-language-identification/index.html">Spoken language identification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html">Pre-trained models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html#whisper">whisper</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html#download-test-waves">Download test waves</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html#test-with-python-apis">Test with Python APIs</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html#android-apks">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/spoken-language-identification/pretrained_models.html#huggingface-space">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/vad/index.html">VAD</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx/pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/online-transducer/index.html">Online transducer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-korean-2024-06-16-korean">sherpa-onnx-streaming-zipformer-korean-2024-06-16 (Korean)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-multi-zh-hans-2023-12-12-chinese">sherpa-onnx-streaming-zipformer-multi-zh-hans-2023-12-12 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#pkufool-icefall-asr-zipformer-streaming-wenetspeech-20230615-chinese">pkufool/icefall-asr-zipformer-streaming-wenetspeech-20230615 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-06-26-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-06-26 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-06-21-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-06-21 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-02-21-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-02-21 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english">csukuangfj/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20 (Bilingual, Chinese + English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french">shaojieli/sherpa-onnx-streaming-zipformer-fr-2023-04-14 (French)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english">sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16 (Bilingual, Chinese + English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-zh-14m-2023-02-23-chinese">csukuangfj/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-20m-2023-02-17-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17 (English)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/online-transducer/conformer-transducer-models.html">Conformer-transducer-based Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-conformer-zh-2023-05-23-chinese">csukuangfj/sherpa-onnx-streaming-conformer-zh-2023-05-23 (Chinese)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/online-transducer/lstm-transducer-models.html">LSTM-transducer-based Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/lstm-transducer-models.html#csukuangfj-sherpa-onnx-lstm-en-2023-02-17-english">csukuangfj/sherpa-onnx-lstm-en-2023-02-17 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-transducer/lstm-transducer-models.html#csukuangfj-sherpa-onnx-lstm-zh-2023-02-20-chinese">csukuangfj/sherpa-onnx-lstm-zh-2023-02-20 (Chinese)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/online-paraformer/index.html">Online paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/online-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-streaming-paraformer-bilingual-zh-en-chinese-english">csukuangfj/sherpa-onnx-streaming-paraformer-bilingual-zh-en (Chinese + English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-streaming-paraformer-trilingual-zh-cantonese-en-chinese-cantonese-english">csukuangfj/sherpa-onnx-streaming-paraformer-trilingual-zh-cantonese-en (Chinese + Cantonese + English)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/online-ctc/index.html">Online CTC models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/online-ctc/zipformer-ctc-models.html">Zipformer-CTC-based Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/online-ctc/zipformer-ctc-models.html#sherpa-onnx-streaming-zipformer-ctc-multi-zh-hans-2023-12-13-chinese">sherpa-onnx-streaming-zipformer-ctc-multi-zh-hans-2023-12-13 (Chinese)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/index.html">Offline transducer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese">sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01 (Japanese, 日语)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-korean-2024-06-24-korean">sherpa-onnx-zipformer-korean-2024-06-24 (Korean, 韩语)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-thai-2024-06-20-thai">sherpa-onnx-zipformer-thai-2024-06-20 (Thai, 泰语)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-cantonese-2024-03-13-cantonese">sherpa-onnx-zipformer-cantonese-2024-03-13 (Cantonese, 粤语)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-gigaspeech-2023-12-12-english">sherpa-onnx-zipformer-gigaspeech-2023-12-12 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#zrjin-sherpa-onnx-zipformer-multi-zh-hans-2023-9-2-chinese">zrjin/sherpa-onnx-zipformer-multi-zh-hans-2023-9-2 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#yfyeung-icefall-asr-cv-corpus-13-0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17-english">yfyeung/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#pkufool-icefall-asr-zipformer-wenetspeech-20230615-chinese">pkufool/icefall-asr-zipformer-wenetspeech-20230615 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-large-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-large-en-2023-06-26 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-small-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-small-en-2023-06-26 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-en-2023-06-26 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#icefall-asr-multidataset-pruned-transducer-stateless7-2023-05-04-english">icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-04-01-english">csukuangfj/sherpa-onnx-zipformer-en-2023-04-01 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-03-30-english">csukuangfj/sherpa-onnx-zipformer-en-2023-03-30 (English)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/conformer-transducer-models.html">Conformer-transducer-based Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-zh-stateless2-2023-05-23-chinese">csukuangfj/sherpa-onnx-conformer-zh-stateless2-2023-05-23 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-zh-2023-05-23-chinese">csukuangfj/sherpa-onnx-conformer-zh-2023-05-23 (Chinese)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-en-2023-03-18-english">csukuangfj/sherpa-onnx-conformer-en-2023-03-18 (English)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/index.html">Offline paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-trilingual-zh-cantonese-en-chinese-english-cantonese">csukuangfj/sherpa-onnx-paraformer-trilingual-zh-cantonese-en (Chinese + English + Cantonese 粤语)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-en-2024-03-09-english">csukuangfj/sherpa-onnx-paraformer-en-2024-03-09 (English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-small-2024-03-09-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-small-2024-03-09 (Chinese + English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2024-03-09 (Chinese + English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-03-28-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28 (Chinese + English)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-09-14-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2023-09-14 (Chinese + English))</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/offline-ctc/index.html">Offline CTC models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/offline-ctc/nemo/index.html">NeMo</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-ctc/nemo/how-to-export.html">How to export models from NeMo to sherpa-onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-ctc/nemo/english.html">English</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/offline-ctc/yesno/index.html">yesno</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/offline-ctc/yesno/index.html#decode-wave-files">Decode wave files</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/telespeech/index.html">TeleSpeech</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/telespeech/how-to-export.html">How to export models from Tele-AI/TeleSpeech-ASR to sherpa-onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/telespeech/how-to-export.html#step-1-export-model-onnx">Step 1: Export model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/telespeech/how-to-export.html#step-2-add-metadata">Step 2: Add metadata</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/telespeech/how-to-export.html#step-3-obtain-tokens-txt">Step 3: Obtain tokens.txt</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/telespeech/models.html">Models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/telespeech/models.html#sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04">sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04 (支持非常多种方言)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/whisper/index.html">Whisper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/whisper/export-onnx.html">Export Whisper to ONNX</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/export-onnx.html#available-models">Available models</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/export-onnx.html#export-to-onnx">Export to onnx</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/whisper/tiny.en.html">tiny.en</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/tiny.en.html#real-time-factor-rtf-on-raspberry-pi-4-model-b">Real-time factor (RTF) on Raspberry Pi 4 Model B</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/whisper/large-v3.html">large-v3</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/large-v3.html#run-with-cpu-float32">Run with CPU (float32)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/large-v3.html#run-with-cpu-int8">Run with CPU (int8)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/large-v3.html#run-with-gpu-float32">Run with GPU (float32)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/large-v3.html#run-with-gpu-int8">Run with GPU (int8)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/large-v3.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/whisper/colab.html">colab</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/colab.html#non-large-models">Non-large models</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/whisper/colab.html#large-models">Large models</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/whisper/huggingface.html">Huggingface space</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/wenet/index.html">WeNet</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/wenet/how-to-export.html">How to export models from WeNet to sherpa-onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/wenet/how-to-export.html#export-for-non-streaming-inference">Export for non-streaming inference</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/wenet/how-to-export.html#export-for-streaming-inference">Export for streaming inference</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/wenet/how-to-export.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/wenet/how-to-export.html#sherpa-onnx-csrc-online-wenet-ctc-model-cc-init-144-head-does-not-exist-in-the-metadata">sherpa-onnx/csrc/online-wenet-ctc-model.cc:Init:144 head does not exist in the metadata</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/pretrained_models/wenet/all-models.html">All models from WeNet</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/pretrained_models/wenet/all-models.html#colab">Colab</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/pretrained_models/small-online-models.html">Small models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/sense-voice/index.html">SenseVoice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/sense-voice/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/sense-voice/export.html">Export SenseVoice to sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/export.html#the-code">The code</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/export.html#test-the-exported-model">Test the exported model</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/export.html#where-to-find-exported-models">Where to find exported models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/sense-voice/pretrained.html">Pre-trained Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/pretrained.html#sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17">sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/pretrained.html#download">Download</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/pretrained.html#decode-a-file-with-model-onnx">Decode a file with model.onnx</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/sense-voice/c-api.html">C API for SenseVoice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/c-api.html#explanations">Explanations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#download-sherpa-onnx">1. Download sherpa-onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#download-the-model">2. Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#build-sherpa-onnx">3. Build sherpa-onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#view-the-build-result">4. View the build result</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#build-the-c-api-example">5. Build the C API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#run-it">6. Run it</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/c-api.html#where-to-find-sense-voice-c-api-c">7. Where to find sense-voice-c-api.c</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/sense-voice/dart-api.html">Dart API for SenseVoice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/dart-api.html#explanations">Explanations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/dart-api.html#download-the-code">1. Download the code</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/dart-api.html#download-the-sherpa-onnx-package">2. Download the sherpa-onnx package</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/dart-api.html#run-it">3. Run it</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/sense-voice/python-api.html">Python API for SenseVoice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/python-api.html#decode-a-file">Decode a file</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/python-api.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/python-api.html#generate-subtitles">Generate subtitles</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/python-api.html#chinese">Chinese</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/python-api.html#english">English</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/sense-voice/python-api.html#websocket-server-and-client-example">WebSocket server and client example</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/python-api.html#start-the-server">1. Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/python-api.html#start-the-client-decode-files-sequentially">2. Start the client (decode files sequentially)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/python-api.html#start-the-client-decode-files-in-parallel">3. Start the client (decode files in parallel)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/sense-voice/python-api.html#start-the-web-browser-client">4. Start the  Web browser client</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx/speaker-identification/index.html">Speaker Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx/tts/index.html">Text-to-speech (TTS)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx/tts/hf-space.html">Huggingface space</a></li>
<li class="toctree-l3"><a class="reference internal" href="onnx/tts/pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html">vits</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#all-models-in-a-single-table">All models in a single table</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#vits-melo-tts-zh-en-chinese-english-1-speaker">vits-melo-tts-zh_en (Chinese + English, 1 speaker)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#vits-piper-en-us-glados-english-1-speaker">vits-piper-en_US-glados (English, 1 speaker)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#vits-piper-en-us-libritts-r-medium-english-904-speakers">vits-piper-en_US-libritts_r-medium (English, 904 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#ljspeech-english-single-speaker">ljspeech (English, single-speaker)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#vctk-english-multi-speaker-109-speakers">VCTK (English, multi-speaker, 109 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#csukuangfj-sherpa-onnx-vits-zh-ll-chinese-5-speakers">csukuangfj/sherpa-onnx-vits-zh-ll (Chinese, 5 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-fanchen-c-chinese-187-speakers">csukuangfj/vits-zh-hf-fanchen-C (Chinese, 187 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-fanchen-wnj-chinese-1-male">csukuangfj/vits-zh-hf-fanchen-wnj (Chinese, 1 male)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-theresa-chinese-804-speakers">csukuangfj/vits-zh-hf-theresa (Chinese, 804 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-eula-chinese-804-speakers">csukuangfj/vits-zh-hf-eula (Chinese, 804 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#aishell3-chinese-multi-speaker-174-speakers">aishell3 (Chinese, multi-speaker, 174 speakers)</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/pretrained_models/vits.html#en-us-lessac-medium-english-single-speaker">en_US-lessac-medium (English, single-speaker)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/tts/wasm/index.html">WebAssembly</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/wasm/install-emscripten.html">Install Emscripten</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/wasm/build.html">Build</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/wasm/hf-spaces.html">Huggingface Spaces (WebAssembly)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/wasm/hf-spaces.html#english-tts">English TTS</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/wasm/hf-spaces.html#german-tts">German TTS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/tts/piper.html">Piper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/piper.html#install-dependencies">Install dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/piper.html#find-the-pre-trained-model-from-piper">Find the pre-trained model from piper</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/piper.html#download-the-pre-trained-model">Download the pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/piper.html#add-meta-data-to-the-onnx-model">Add meta data to the onnx model</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/piper.html#download-espeak-ng-data">Download espeak-ng-data</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/piper.html#test-your-converted-model">Test your converted model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/tts/mms.html">MMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/mms.html#install-dependencies">Install dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/mms.html#download-the-model-file">Download the model file</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/mms.html#download-mms-source-code">Download MMS source code</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/mms.html#convert-the-model">Convert the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/mms.html#use-the-converted-model">Use the converted model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx/tts/faq.html">Frequently Asked Question (FAQs)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/faq.html#is-there-a-colab-notebook">Is there a colab notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/faq.html#how-to-enable-utf-8-on-windows">How to enable UTF-8 on Windows</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/faq.html#how-to-install-sherpa-onnx-for-tts">How to install sherpa-onnx for TTS</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/faq.html#for-python-users">For Python users</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx/tts/faq.html#build-from-source">Build from source</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/faq.html#where-to-get-pre-trained-tts-models">Where to get pre-trained TTS models</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx/tts/faq.html#how-to-handle-oovs">How to handle OOVs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="triton/overview.html">Triton</a><ul>
<li class="toctree-l2"><a class="reference internal" href="triton/installation/index.html">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="triton/installation/index.html#build-triton-image">Build Triton Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="triton/installation/index.html#launch-a-inference-container">Launch a inference container</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="triton/server/index.html">Triton-server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="triton/server/index.html#deploy-streaming-asr-models-with-onnx">Deploy streaming ASR models with Onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="triton/server/index.html#deploy-offline-asr-models-with-torchscript">Deploy offline ASR models with torchscript</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="triton/client/index.html">Triton-client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="triton/client/index.html#send-requests-using-client">Send requests using client</a></li>
<li class="toctree-l3"><a class="reference internal" href="triton/client/index.html#decode-manifests">Decode manifests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="triton/perf/index.html">Perf Analyzer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="triton/perf/index.html#generate-input-data-from-audio-files">Generate Input Data from Audio Files</a></li>
<li class="toctree-l3"><a class="reference internal" href="triton/perf/index.html#test-throughput-using-perf-analyzer">Test Throughput using Perf Analyzer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="triton/trt/index.html">TensorRT acceleration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="triton/trt/index.html#preparation">Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="triton/trt/index.html#model-export">Model export</a></li>
<li class="toctree-l3"><a class="reference internal" href="triton/trt/index.html#benchmark-for-conformer-trt-encoder-vs-onnx">Benchmark for Conformer TRT encoder vs ONNX</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="intro.html" class="btn btn-neutral float-right" title="Introduction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2024, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>